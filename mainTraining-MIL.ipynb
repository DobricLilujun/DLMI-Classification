{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIL - Multi instance Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3859/1677006143.py:28: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import copy\n",
    "import re\n",
    "import yaml\n",
    "import uuid\n",
    "import warnings\n",
    "import time\n",
    "import inspect\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import partial, reduce\n",
    "from random import shuffle\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, Resize\n",
    "from torchvision.models.resnet import ResNet, BasicBlock\n",
    "from torchvision.datasets import MNIST\n",
    "from tqdm.autonotebook import tqdm\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn import metrics as mtx\n",
    "from sklearn import model_selection as ms\n",
    "import os\n",
    "import shutil\n",
    "import warnings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import torch.nn.init as init\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data is not standardized because it has two different format\n",
    "def calculate_age(dob_str):\n",
    "    formats = [\"%m/%d/%Y\", \"%d-%m-%Y\"]  # Two different format at the same time!\n",
    "    for format_string in formats:\n",
    "        try:\n",
    "            dob_date = datetime.strptime(dob_str, format_string)\n",
    "            current_date = datetime.now()\n",
    "            age = (\n",
    "                current_date.year\n",
    "                - dob_date.year\n",
    "                - (\n",
    "                    (current_date.month, current_date.day)\n",
    "                    < (dob_date.month, dob_date.day)\n",
    "                )\n",
    "            )\n",
    "            return age\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "\n",
    "# The data for the gender is not consistent F or f or M or m\n",
    "def encode_gender(gender):\n",
    "    if gender == \"F\" or gender == \"f\":  # Two different gender value F and f ....\n",
    "        return 0\n",
    "    elif gender == \"M\" or gender == \"m\":\n",
    "        return 1\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Invalid gender value. Expected 'F' or 'M', but received: {}\".format(gender)\n",
    "        )\n",
    "\n",
    "\n",
    "# The dataset for the multi instance training - Every patient has a bag of images\n",
    "class DLMICustomDataset(Dataset):\n",
    "    def __init__(self, data, transform=None, flag=\"trainset\", max_images=80):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "        self.flag = flag\n",
    "        self.max_images = max_images\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    # Get items by the index\n",
    "    def __getitem__(self, idx):\n",
    "        patient_ID = self.data.iloc[idx, 1]  # Get patient ID\n",
    "        img_path_folder = \"data/raw/\" + self.flag + \"/\" + str(patient_ID) + \"/\"\n",
    "\n",
    "        images = []\n",
    "        images_loaded = 0\n",
    "        # Load images and make sure that the loaded images bag has the same number of images\n",
    "        for filename in os.listdir(img_path_folder):\n",
    "            if filename.endswith(\".jpg\"):\n",
    "                img_path = os.path.join(img_path_folder, filename)\n",
    "                image = Image.open(img_path).convert(\"RGB\")\n",
    "                if self.transform:\n",
    "                    image = self.transform(image)\n",
    "                images.append(image)\n",
    "                images_loaded += 1\n",
    "                if (\n",
    "                    images_loaded >= self.max_images\n",
    "                ):  # Stop loading if max_images reached\n",
    "                    break\n",
    "        if len(images) == 0:\n",
    "            images.append(torch.zeros((3, 224, 224)))  # Placeholder image\n",
    "\n",
    "        # If not enough images founded, randomly pick image from the loaded images\n",
    "        while len(images) < self.max_images:\n",
    "            random_image = random.choice(images)\n",
    "            images.append(random_image)\n",
    "\n",
    "        label = torch.tensor(self.data.iloc[idx, 2])\n",
    "        gender = torch.tensor(encode_gender(self.data.iloc[idx, 3]), dtype=torch.long)\n",
    "        age = torch.tensor(calculate_age(self.data.iloc[idx, 4]), dtype=torch.float32)\n",
    "        lymph_count = torch.tensor(self.data.iloc[idx, 5], dtype=torch.float32)\n",
    "        clinical_data = torch.stack((gender, age, lymph_count))\n",
    "        # Final size is (num_images, channels, height, width)\n",
    "        return torch.stack(images), clinical_data, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MILModel(nn.Module):\n",
    "    def __init__(self, mlp_input_dim, mlp_hidden_dim):\n",
    "        super(MILModel, self).__init__()\n",
    "        self.resnet18 = models.resnet18(pretrained=True)\n",
    "        for param in self.resnet18.parameters():\n",
    "            param.requires_grad = False\n",
    "        num_ftrs = self.resnet18.fc.in_features\n",
    "        self.resnet18.fc = nn.Linear(num_ftrs, num_ftrs)  # One trainable layers\n",
    "        self.linear_classifier = nn.Sequential(\n",
    "            nn.Linear(num_ftrs, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1),\n",
    "        )  # One classifier with bias\n",
    "        self.mlp = MLP(input_dim=mlp_input_dim, hidden_dim=mlp_hidden_dim, output_dim=1)\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "    # Batch imaging forwarding for bags batchsize*imagesnum*channel*width * height\n",
    "    def forward_images(self, image_data):\n",
    "        score_output = []\n",
    "        for batch in image_data:\n",
    "            batch_encoded_images = []\n",
    "            for image in batch:\n",
    "                image = image.unsqueeze(0)\n",
    "                features = self.resnet18(image)\n",
    "                # Mean pooling to do max pooling or LSE pooling\n",
    "                batch_encoded_images.append(features)\n",
    "            feature_extracted = torch.stack(batch_encoded_images)\n",
    "            features = torch.mean(feature_extracted, dim=0)  # mean pooling\n",
    "            score_output.append(self.linear_classifier(features).view(-1))\n",
    "        return torch.stack(score_output)\n",
    "\n",
    "    def forward(self, image_data, clinical_data):\n",
    "        batch_size, num_images, channels, height, width = image_data.size()\n",
    "        image_output = self.forward_images(image_data)\n",
    "        mlp_output = self.mlp(clinical_data)\n",
    "        return image_output, mlp_output\n",
    "\n",
    "    def loss_function(self, image_output, clinical_output, labels):\n",
    "        image_loss = F.binary_cross_entropy_with_logits(\n",
    "            image_output, labels\n",
    "        )  # loss should be calculated before sigmoid for stable trainging\n",
    "        clinical_loss = F.binary_cross_entropy_with_logits(\n",
    "            clinical_output, labels\n",
    "        )  # loss should be calculated before sigmoid for stable trainging\n",
    "\n",
    "        return (image_loss + clinical_loss) / 2\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.activate = nn.Sigmoid()\n",
    "\n",
    "        # Initialize the weights for the linear layers\n",
    "        init.xavier_uniform_(self.fc1.weight)\n",
    "        init.xavier_uniform_(self.fc2.weight)\n",
    "        init.xavier_uniform_(self.fc3.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(outputs, labels):\n",
    "    predicted_classes = torch.argmax(outputs, dim=1)\n",
    "    true_classes = torch.argmax(labels, dim=1)\n",
    "    accuracy = (predicted_classes == true_classes).float().mean().item()\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trianing is on cuda\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import DatasetFolder\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import json\n",
    "\n",
    "# from stanfordnlp.training import trainset_splitter\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Trianing is on \" + str(device))\n",
    "# Define hyperparameters\n",
    "hyperparameters = {\n",
    "    \"mlp_input_dim\": 3,\n",
    "    \"mlp_hidden_dim\": 10,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"batch_size\": 12,\n",
    "    \"num_epochs\": 500,\n",
    "}\n",
    "\n",
    "model = MILModel(\n",
    "    mlp_input_dim=hyperparameters[\"mlp_input_dim\"],\n",
    "    mlp_hidden_dim=hyperparameters[\"mlp_hidden_dim\"],\n",
    ").to(device)\n",
    "\n",
    "with open(f\"hyperparameters.json\", \"w\") as json_file:\n",
    "    json.dump(hyperparameters, json_file)\n",
    "\n",
    "current_time = time.strftime(\"%Y-%m-%d_%H-%M-%S\", time.localtime())\n",
    "log_dir = os.path.join(\"logs\", current_time)\n",
    "writer = SummaryWriter(log_dir)\n",
    "\n",
    "data = pd.read_csv(\n",
    "    \"/home/lujun/local/DLMI-Classification/data/raw/clinical_annotation.csv\"\n",
    ")\n",
    "train_data = data[data[\"LABEL\"] != -1]\n",
    "test_data = data[data[\"LABEL\"] == -1]\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# training : validation : test = 130 : 33 : 42\n",
    "training_dataset = DLMICustomDataset(\n",
    "    data=train_data, transform=transform, flag=\"trainset\"\n",
    ")  # 130\n",
    "\n",
    "test_dataset = DLMICustomDataset(\n",
    "    data=test_data, transform=transform, flag=\"testset\"\n",
    ")  # 42\n",
    "\n",
    "train_size = int(0.8 * len(training_dataset))\n",
    "val_size = len(training_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(training_dataset, [train_size, val_size])\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=hyperparameters[\"batch_size\"], shuffle=True\n",
    ")  # 130\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=hyperparameters[\"batch_size\"], shuffle=False\n",
    ")  # 33\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=hyperparameters[\"batch_size\"], shuffle=False\n",
    ")\n",
    "# Every item: max-images * channel number * width * height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Loss: 1.1171\n",
      "Epoch 1 Total Loss: 13.2016, Accuracy: 50.77%\n",
      "Epoch [1/500], Train Loss: 1.1171, Val Loss: 1.2485, Val Accuracy: 0.4848\n",
      "Epoch [2/500], Loss: 1.1015\n",
      "Epoch 2 Total Loss: 13.0172, Accuracy: 51.54%\n",
      "Epoch [2/500], Train Loss: 1.1015, Val Loss: 1.2334, Val Accuracy: 0.4848\n",
      "Epoch [3/500], Loss: 1.0889\n",
      "Epoch 3 Total Loss: 12.8684, Accuracy: 51.54%\n",
      "Epoch [3/500], Train Loss: 1.0889, Val Loss: 1.2142, Val Accuracy: 0.4848\n",
      "Epoch [4/500], Loss: 1.0768\n",
      "Epoch 4 Total Loss: 12.7256, Accuracy: 51.54%\n",
      "Epoch [4/500], Train Loss: 1.0768, Val Loss: 1.2046, Val Accuracy: 0.4848\n",
      "Epoch [5/500], Loss: 1.0666\n",
      "Epoch 5 Total Loss: 12.6057, Accuracy: 52.31%\n",
      "Epoch [5/500], Train Loss: 1.0666, Val Loss: 1.1926, Val Accuracy: 0.4545\n",
      "Epoch [6/500], Loss: 1.0564\n",
      "Epoch 6 Total Loss: 12.4846, Accuracy: 52.31%\n",
      "Epoch [6/500], Train Loss: 1.0564, Val Loss: 1.1825, Val Accuracy: 0.4545\n",
      "Epoch [7/500], Loss: 1.0477\n",
      "Epoch 7 Total Loss: 12.3822, Accuracy: 52.31%\n",
      "Epoch [7/500], Train Loss: 1.0477, Val Loss: 1.1676, Val Accuracy: 0.4545\n",
      "Epoch [8/500], Loss: 1.0384\n",
      "Epoch 8 Total Loss: 12.2726, Accuracy: 52.31%\n",
      "Epoch [8/500], Train Loss: 1.0384, Val Loss: 1.1565, Val Accuracy: 0.4545\n",
      "Epoch [9/500], Loss: 1.0299\n",
      "Epoch 9 Total Loss: 12.1711, Accuracy: 52.31%\n",
      "Epoch [9/500], Train Loss: 1.0299, Val Loss: 1.1473, Val Accuracy: 0.4545\n",
      "Epoch [10/500], Loss: 1.0219\n",
      "Epoch 10 Total Loss: 12.0767, Accuracy: 54.62%\n",
      "Epoch [10/500], Train Loss: 1.0219, Val Loss: 1.1398, Val Accuracy: 0.4545\n",
      "Epoch [11/500], Loss: 1.0145\n",
      "Epoch 11 Total Loss: 11.9895, Accuracy: 54.62%\n",
      "Epoch [11/500], Train Loss: 1.0145, Val Loss: 1.1316, Val Accuracy: 0.4545\n",
      "Epoch [12/500], Loss: 1.0057\n",
      "Epoch 12 Total Loss: 11.8855, Accuracy: 54.62%\n",
      "Epoch [12/500], Train Loss: 1.0057, Val Loss: 1.1202, Val Accuracy: 0.4545\n",
      "Epoch [13/500], Loss: 0.9982\n",
      "Epoch 13 Total Loss: 11.7966, Accuracy: 54.62%\n",
      "Epoch [13/500], Train Loss: 0.9982, Val Loss: 1.1114, Val Accuracy: 0.4545\n",
      "Epoch [14/500], Loss: 0.9902\n",
      "Epoch 14 Total Loss: 11.7019, Accuracy: 54.62%\n",
      "Epoch [14/500], Train Loss: 0.9902, Val Loss: 1.1059, Val Accuracy: 0.4545\n",
      "Epoch [15/500], Loss: 0.9823\n",
      "Epoch 15 Total Loss: 11.6090, Accuracy: 53.08%\n",
      "Epoch [15/500], Train Loss: 0.9823, Val Loss: 1.0962, Val Accuracy: 0.4545\n",
      "Epoch [16/500], Loss: 0.9749\n",
      "Epoch 16 Total Loss: 11.5221, Accuracy: 53.08%\n",
      "Epoch [16/500], Train Loss: 0.9749, Val Loss: 1.0867, Val Accuracy: 0.4545\n",
      "Epoch [17/500], Loss: 0.9677\n",
      "Epoch 17 Total Loss: 11.4367, Accuracy: 53.08%\n",
      "Epoch [17/500], Train Loss: 0.9677, Val Loss: 1.0793, Val Accuracy: 0.4545\n",
      "Epoch [18/500], Loss: 0.9595\n",
      "Epoch 18 Total Loss: 11.3393, Accuracy: 53.08%\n",
      "Epoch [18/500], Train Loss: 0.9595, Val Loss: 1.0723, Val Accuracy: 0.4545\n",
      "Epoch [19/500], Loss: 0.9526\n",
      "Epoch 19 Total Loss: 11.2586, Accuracy: 53.08%\n",
      "Epoch [19/500], Train Loss: 0.9526, Val Loss: 1.0616, Val Accuracy: 0.4545\n",
      "Epoch [20/500], Loss: 0.9450\n",
      "Epoch 20 Total Loss: 11.1677, Accuracy: 53.08%\n",
      "Epoch [20/500], Train Loss: 0.9450, Val Loss: 1.0541, Val Accuracy: 0.4545\n",
      "Epoch [21/500], Loss: 0.9377\n",
      "Epoch 21 Total Loss: 11.0823, Accuracy: 53.85%\n",
      "Epoch [21/500], Train Loss: 0.9377, Val Loss: 1.0442, Val Accuracy: 0.4242\n",
      "Epoch [22/500], Loss: 0.9307\n",
      "Epoch 22 Total Loss: 10.9995, Accuracy: 53.85%\n",
      "Epoch [22/500], Train Loss: 0.9307, Val Loss: 1.0390, Val Accuracy: 0.4242\n",
      "Epoch [23/500], Loss: 0.9234\n",
      "Epoch 23 Total Loss: 10.9130, Accuracy: 53.85%\n",
      "Epoch [23/500], Train Loss: 0.9234, Val Loss: 1.0313, Val Accuracy: 0.4545\n",
      "Epoch [24/500], Loss: 0.9165\n",
      "Epoch 24 Total Loss: 10.8313, Accuracy: 55.38%\n",
      "Epoch [24/500], Train Loss: 0.9165, Val Loss: 1.0215, Val Accuracy: 0.4545\n",
      "Epoch [25/500], Loss: 0.9094\n",
      "Epoch 25 Total Loss: 10.7479, Accuracy: 54.62%\n",
      "Epoch [25/500], Train Loss: 0.9094, Val Loss: 1.0145, Val Accuracy: 0.4242\n",
      "Epoch [26/500], Loss: 0.9027\n",
      "Epoch 26 Total Loss: 10.6681, Accuracy: 55.38%\n",
      "Epoch [26/500], Train Loss: 0.9027, Val Loss: 1.0060, Val Accuracy: 0.4545\n",
      "Epoch [27/500], Loss: 0.8958\n",
      "Epoch 27 Total Loss: 10.5862, Accuracy: 56.15%\n",
      "Epoch [27/500], Train Loss: 0.8958, Val Loss: 0.9990, Val Accuracy: 0.4545\n",
      "Epoch [28/500], Loss: 0.8891\n",
      "Epoch 28 Total Loss: 10.5079, Accuracy: 56.92%\n",
      "Epoch [28/500], Train Loss: 0.8891, Val Loss: 0.9904, Val Accuracy: 0.4545\n",
      "Epoch [29/500], Loss: 0.8824\n",
      "Epoch 29 Total Loss: 10.4279, Accuracy: 56.92%\n",
      "Epoch [29/500], Train Loss: 0.8824, Val Loss: 0.9839, Val Accuracy: 0.4848\n",
      "Epoch [30/500], Loss: 0.8757\n",
      "Epoch 30 Total Loss: 10.3494, Accuracy: 56.92%\n",
      "Epoch [30/500], Train Loss: 0.8757, Val Loss: 0.9755, Val Accuracy: 0.4848\n",
      "Epoch [31/500], Loss: 0.8691\n",
      "Epoch 31 Total Loss: 10.2711, Accuracy: 56.92%\n",
      "Epoch [31/500], Train Loss: 0.8691, Val Loss: 0.9696, Val Accuracy: 0.4848\n",
      "Epoch [32/500], Loss: 0.8627\n",
      "Epoch 32 Total Loss: 10.1960, Accuracy: 56.15%\n",
      "Epoch [32/500], Train Loss: 0.8627, Val Loss: 0.9621, Val Accuracy: 0.4848\n",
      "Epoch [33/500], Loss: 0.8564\n",
      "Epoch 33 Total Loss: 10.1205, Accuracy: 56.92%\n",
      "Epoch [33/500], Train Loss: 0.8564, Val Loss: 0.9519, Val Accuracy: 0.5152\n",
      "Epoch [34/500], Loss: 0.8506\n",
      "Epoch 34 Total Loss: 10.0523, Accuracy: 56.92%\n",
      "Epoch [34/500], Train Loss: 0.8506, Val Loss: 0.9458, Val Accuracy: 0.5152\n",
      "Epoch [35/500], Loss: 0.8440\n",
      "Epoch 35 Total Loss: 9.9750, Accuracy: 56.92%\n",
      "Epoch [35/500], Train Loss: 0.8440, Val Loss: 0.9401, Val Accuracy: 0.5152\n",
      "Epoch [36/500], Loss: 0.8378\n",
      "Epoch 36 Total Loss: 9.9014, Accuracy: 56.92%\n",
      "Epoch [36/500], Train Loss: 0.8378, Val Loss: 0.9312, Val Accuracy: 0.5152\n",
      "Epoch [37/500], Loss: 0.8320\n",
      "Epoch 37 Total Loss: 9.8323, Accuracy: 57.69%\n",
      "Epoch [37/500], Train Loss: 0.8320, Val Loss: 0.9264, Val Accuracy: 0.5152\n",
      "Epoch [38/500], Loss: 0.8263\n",
      "Epoch 38 Total Loss: 9.7650, Accuracy: 57.69%\n",
      "Epoch [38/500], Train Loss: 0.8263, Val Loss: 0.9204, Val Accuracy: 0.5152\n",
      "Epoch [39/500], Loss: 0.8200\n",
      "Epoch 39 Total Loss: 9.6913, Accuracy: 57.69%\n",
      "Epoch [39/500], Train Loss: 0.8200, Val Loss: 0.9142, Val Accuracy: 0.5152\n",
      "Epoch [40/500], Loss: 0.8143\n",
      "Epoch 40 Total Loss: 9.6239, Accuracy: 58.46%\n",
      "Epoch [40/500], Train Loss: 0.8143, Val Loss: 0.9079, Val Accuracy: 0.5152\n",
      "Epoch [41/500], Loss: 0.8090\n",
      "Epoch 41 Total Loss: 9.5609, Accuracy: 58.46%\n",
      "Epoch [41/500], Train Loss: 0.8090, Val Loss: 0.8960, Val Accuracy: 0.4848\n",
      "Epoch [42/500], Loss: 0.8029\n",
      "Epoch 42 Total Loss: 9.4894, Accuracy: 59.23%\n",
      "Epoch [42/500], Train Loss: 0.8029, Val Loss: 0.8920, Val Accuracy: 0.5152\n",
      "Epoch [43/500], Loss: 0.7976\n",
      "Epoch 43 Total Loss: 9.4267, Accuracy: 59.23%\n",
      "Epoch [43/500], Train Loss: 0.7976, Val Loss: 0.8856, Val Accuracy: 0.5152\n",
      "Epoch [44/500], Loss: 0.7919\n",
      "Epoch 44 Total Loss: 9.3583, Accuracy: 59.23%\n",
      "Epoch [44/500], Train Loss: 0.7919, Val Loss: 0.8813, Val Accuracy: 0.4545\n",
      "Epoch [45/500], Loss: 0.7867\n",
      "Epoch 45 Total Loss: 9.2974, Accuracy: 59.23%\n",
      "Epoch [45/500], Train Loss: 0.7867, Val Loss: 0.8733, Val Accuracy: 0.4545\n",
      "Epoch [46/500], Loss: 0.7815\n",
      "Epoch 46 Total Loss: 9.2356, Accuracy: 59.23%\n",
      "Epoch [46/500], Train Loss: 0.7815, Val Loss: 0.8677, Val Accuracy: 0.4545\n",
      "Epoch [47/500], Loss: 0.7762\n",
      "Epoch 47 Total Loss: 9.1729, Accuracy: 59.23%\n",
      "Epoch [47/500], Train Loss: 0.7762, Val Loss: 0.8590, Val Accuracy: 0.4545\n",
      "Epoch [48/500], Loss: 0.7710\n",
      "Epoch 48 Total Loss: 9.1116, Accuracy: 59.23%\n",
      "Epoch [48/500], Train Loss: 0.7710, Val Loss: 0.8546, Val Accuracy: 0.4545\n",
      "Epoch [49/500], Loss: 0.7661\n",
      "Epoch 49 Total Loss: 9.0539, Accuracy: 60.00%\n",
      "Epoch [49/500], Train Loss: 0.7661, Val Loss: 0.8494, Val Accuracy: 0.4545\n",
      "Epoch [50/500], Loss: 0.7611\n",
      "Epoch 50 Total Loss: 8.9949, Accuracy: 58.46%\n",
      "Epoch [50/500], Train Loss: 0.7611, Val Loss: 0.8454, Val Accuracy: 0.4545\n",
      "Epoch [51/500], Loss: 0.7566\n",
      "Epoch 51 Total Loss: 8.9416, Accuracy: 59.23%\n",
      "Epoch [51/500], Train Loss: 0.7566, Val Loss: 0.8385, Val Accuracy: 0.4545\n",
      "Epoch [52/500], Loss: 0.7516\n",
      "Epoch 52 Total Loss: 8.8821, Accuracy: 60.00%\n",
      "Epoch [52/500], Train Loss: 0.7516, Val Loss: 0.8295, Val Accuracy: 0.5152\n",
      "Epoch [53/500], Loss: 0.7466\n",
      "Epoch 53 Total Loss: 8.8232, Accuracy: 60.77%\n",
      "Epoch [53/500], Train Loss: 0.7466, Val Loss: 0.8265, Val Accuracy: 0.5152\n",
      "Epoch [54/500], Loss: 0.7421\n",
      "Epoch 54 Total Loss: 8.7706, Accuracy: 60.00%\n",
      "Epoch [54/500], Train Loss: 0.7421, Val Loss: 0.8203, Val Accuracy: 0.5152\n",
      "Epoch [55/500], Loss: 0.7373\n",
      "Epoch 55 Total Loss: 8.7138, Accuracy: 60.00%\n",
      "Epoch [55/500], Train Loss: 0.7373, Val Loss: 0.8168, Val Accuracy: 0.5152\n",
      "Epoch [56/500], Loss: 0.7335\n",
      "Epoch 56 Total Loss: 8.6689, Accuracy: 60.00%\n",
      "Epoch [56/500], Train Loss: 0.7335, Val Loss: 0.8081, Val Accuracy: 0.5152\n",
      "Epoch [57/500], Loss: 0.7288\n",
      "Epoch 57 Total Loss: 8.6130, Accuracy: 59.23%\n",
      "Epoch [57/500], Train Loss: 0.7288, Val Loss: 0.8021, Val Accuracy: 0.5152\n",
      "Epoch [58/500], Loss: 0.7243\n",
      "Epoch 58 Total Loss: 8.5594, Accuracy: 59.23%\n",
      "Epoch [58/500], Train Loss: 0.7243, Val Loss: 0.8027, Val Accuracy: 0.5152\n",
      "Epoch [59/500], Loss: 0.7202\n",
      "Epoch 59 Total Loss: 8.5118, Accuracy: 60.00%\n",
      "Epoch [59/500], Train Loss: 0.7202, Val Loss: 0.7955, Val Accuracy: 0.5152\n",
      "Epoch [60/500], Loss: 0.7160\n",
      "Epoch 60 Total Loss: 8.4623, Accuracy: 60.00%\n",
      "Epoch [60/500], Train Loss: 0.7160, Val Loss: 0.7908, Val Accuracy: 0.5152\n",
      "Epoch [61/500], Loss: 0.7120\n",
      "Epoch 61 Total Loss: 8.4145, Accuracy: 60.00%\n",
      "Epoch [61/500], Train Loss: 0.7120, Val Loss: 0.7852, Val Accuracy: 0.5455\n",
      "Epoch [62/500], Loss: 0.7082\n",
      "Epoch 62 Total Loss: 8.3695, Accuracy: 60.00%\n",
      "Epoch [62/500], Train Loss: 0.7082, Val Loss: 0.7806, Val Accuracy: 0.5455\n",
      "Epoch [63/500], Loss: 0.7043\n",
      "Epoch 63 Total Loss: 8.3233, Accuracy: 60.77%\n",
      "Epoch [63/500], Train Loss: 0.7043, Val Loss: 0.7738, Val Accuracy: 0.5455\n",
      "Epoch [64/500], Loss: 0.7006\n",
      "Epoch 64 Total Loss: 8.2796, Accuracy: 60.00%\n",
      "Epoch [64/500], Train Loss: 0.7006, Val Loss: 0.7697, Val Accuracy: 0.5455\n",
      "Epoch [65/500], Loss: 0.6965\n",
      "Epoch 65 Total Loss: 8.2316, Accuracy: 61.54%\n",
      "Epoch [65/500], Train Loss: 0.6965, Val Loss: 0.7649, Val Accuracy: 0.5455\n",
      "Epoch [66/500], Loss: 0.6929\n",
      "Epoch 66 Total Loss: 8.1892, Accuracy: 62.31%\n",
      "Epoch [66/500], Train Loss: 0.6929, Val Loss: 0.7629, Val Accuracy: 0.5455\n",
      "Epoch [67/500], Loss: 0.6894\n",
      "Epoch 67 Total Loss: 8.1470, Accuracy: 62.31%\n",
      "Epoch [67/500], Train Loss: 0.6894, Val Loss: 0.7575, Val Accuracy: 0.5455\n",
      "Epoch [68/500], Loss: 0.6859\n",
      "Epoch 68 Total Loss: 8.1062, Accuracy: 62.31%\n",
      "Epoch [68/500], Train Loss: 0.6859, Val Loss: 0.7512, Val Accuracy: 0.5455\n",
      "Epoch [69/500], Loss: 0.6822\n",
      "Epoch 69 Total Loss: 8.0627, Accuracy: 62.31%\n",
      "Epoch [69/500], Train Loss: 0.6822, Val Loss: 0.7470, Val Accuracy: 0.5455\n",
      "Epoch [70/500], Loss: 0.6789\n",
      "Epoch 70 Total Loss: 8.0234, Accuracy: 62.31%\n",
      "Epoch [70/500], Train Loss: 0.6789, Val Loss: 0.7442, Val Accuracy: 0.5455\n",
      "Epoch [71/500], Loss: 0.6757\n",
      "Epoch 71 Total Loss: 7.9861, Accuracy: 62.31%\n",
      "Epoch [71/500], Train Loss: 0.6757, Val Loss: 0.7381, Val Accuracy: 0.5455\n",
      "Epoch [72/500], Loss: 0.6725\n",
      "Epoch 72 Total Loss: 7.9479, Accuracy: 62.31%\n",
      "Epoch [72/500], Train Loss: 0.6725, Val Loss: 0.7364, Val Accuracy: 0.5455\n",
      "Epoch [73/500], Loss: 0.6691\n",
      "Epoch 73 Total Loss: 7.9079, Accuracy: 62.31%\n",
      "Epoch [73/500], Train Loss: 0.6691, Val Loss: 0.7328, Val Accuracy: 0.5455\n",
      "Epoch [74/500], Loss: 0.6659\n",
      "Epoch 74 Total Loss: 7.8701, Accuracy: 62.31%\n",
      "Epoch [74/500], Train Loss: 0.6659, Val Loss: 0.7288, Val Accuracy: 0.5455\n",
      "Epoch [75/500], Loss: 0.6631\n",
      "Epoch 75 Total Loss: 7.8366, Accuracy: 63.08%\n",
      "Epoch [75/500], Train Loss: 0.6631, Val Loss: 0.7241, Val Accuracy: 0.5455\n",
      "Epoch [76/500], Loss: 0.6600\n",
      "Epoch 76 Total Loss: 7.8000, Accuracy: 63.08%\n",
      "Epoch [76/500], Train Loss: 0.6600, Val Loss: 0.7221, Val Accuracy: 0.5455\n",
      "Epoch [77/500], Loss: 0.6569\n",
      "Epoch 77 Total Loss: 7.7638, Accuracy: 63.08%\n",
      "Epoch [77/500], Train Loss: 0.6569, Val Loss: 0.7169, Val Accuracy: 0.5455\n",
      "Epoch [78/500], Loss: 0.6542\n",
      "Epoch 78 Total Loss: 7.7311, Accuracy: 63.85%\n",
      "Epoch [78/500], Train Loss: 0.6542, Val Loss: 0.7114, Val Accuracy: 0.5455\n",
      "Epoch [79/500], Loss: 0.6515\n",
      "Epoch 79 Total Loss: 7.6997, Accuracy: 63.08%\n",
      "Epoch [79/500], Train Loss: 0.6515, Val Loss: 0.7089, Val Accuracy: 0.5455\n",
      "Epoch [80/500], Loss: 0.6486\n",
      "Epoch 80 Total Loss: 7.6647, Accuracy: 63.08%\n",
      "Epoch [80/500], Train Loss: 0.6486, Val Loss: 0.7063, Val Accuracy: 0.5758\n",
      "Epoch [81/500], Loss: 0.6459\n",
      "Epoch 81 Total Loss: 7.6328, Accuracy: 63.08%\n",
      "Epoch [81/500], Train Loss: 0.6459, Val Loss: 0.7012, Val Accuracy: 0.5455\n",
      "Epoch [82/500], Loss: 0.6432\n",
      "Epoch 82 Total Loss: 7.6016, Accuracy: 63.85%\n",
      "Epoch [82/500], Train Loss: 0.6432, Val Loss: 0.6984, Val Accuracy: 0.6061\n",
      "Epoch [83/500], Loss: 0.6408\n",
      "Epoch 83 Total Loss: 7.5732, Accuracy: 63.85%\n",
      "Epoch [83/500], Train Loss: 0.6408, Val Loss: 0.6926, Val Accuracy: 0.5758\n",
      "Epoch [84/500], Loss: 0.6383\n",
      "Epoch 84 Total Loss: 7.5430, Accuracy: 63.85%\n",
      "Epoch [84/500], Train Loss: 0.6383, Val Loss: 0.6915, Val Accuracy: 0.5758\n",
      "Epoch [85/500], Loss: 0.6362\n",
      "Epoch 85 Total Loss: 7.5190, Accuracy: 64.62%\n",
      "Epoch [85/500], Train Loss: 0.6362, Val Loss: 0.6892, Val Accuracy: 0.5758\n",
      "Epoch [86/500], Loss: 0.6335\n",
      "Epoch 86 Total Loss: 7.4866, Accuracy: 65.38%\n",
      "Epoch [86/500], Train Loss: 0.6335, Val Loss: 0.6866, Val Accuracy: 0.6061\n",
      "Epoch [87/500], Loss: 0.6313\n",
      "Epoch 87 Total Loss: 7.4607, Accuracy: 65.38%\n",
      "Epoch [87/500], Train Loss: 0.6313, Val Loss: 0.6855, Val Accuracy: 0.5758\n",
      "Epoch [88/500], Loss: 0.6288\n",
      "Epoch 88 Total Loss: 7.4316, Accuracy: 65.38%\n",
      "Epoch [88/500], Train Loss: 0.6288, Val Loss: 0.6811, Val Accuracy: 0.5758\n",
      "Epoch [89/500], Loss: 0.6271\n",
      "Epoch 89 Total Loss: 7.4109, Accuracy: 65.38%\n",
      "Epoch [89/500], Train Loss: 0.6271, Val Loss: 0.6740, Val Accuracy: 0.5758\n",
      "Epoch [90/500], Loss: 0.6247\n",
      "Epoch 90 Total Loss: 7.3827, Accuracy: 66.92%\n",
      "Epoch [90/500], Train Loss: 0.6247, Val Loss: 0.6752, Val Accuracy: 0.5758\n",
      "Epoch [91/500], Loss: 0.6224\n",
      "Epoch 91 Total Loss: 7.3560, Accuracy: 66.92%\n",
      "Epoch [91/500], Train Loss: 0.6224, Val Loss: 0.6721, Val Accuracy: 0.5758\n",
      "Epoch [92/500], Loss: 0.6205\n",
      "Epoch 92 Total Loss: 7.3331, Accuracy: 65.38%\n",
      "Epoch [92/500], Train Loss: 0.6205, Val Loss: 0.6678, Val Accuracy: 0.5758\n",
      "Epoch [93/500], Loss: 0.6184\n",
      "Epoch 93 Total Loss: 7.3084, Accuracy: 65.38%\n",
      "Epoch [93/500], Train Loss: 0.6184, Val Loss: 0.6660, Val Accuracy: 0.5758\n",
      "Epoch [94/500], Loss: 0.6165\n",
      "Epoch 94 Total Loss: 7.2855, Accuracy: 65.38%\n",
      "Epoch [94/500], Train Loss: 0.6165, Val Loss: 0.6627, Val Accuracy: 0.5758\n",
      "Epoch [95/500], Loss: 0.6147\n",
      "Epoch 95 Total Loss: 7.2646, Accuracy: 64.62%\n",
      "Epoch [95/500], Train Loss: 0.6147, Val Loss: 0.6633, Val Accuracy: 0.5758\n",
      "Epoch [96/500], Loss: 0.6127\n",
      "Epoch 96 Total Loss: 7.2414, Accuracy: 63.85%\n",
      "Epoch [96/500], Train Loss: 0.6127, Val Loss: 0.6580, Val Accuracy: 0.5758\n",
      "Epoch [97/500], Loss: 0.6109\n",
      "Epoch 97 Total Loss: 7.2199, Accuracy: 63.85%\n",
      "Epoch [97/500], Train Loss: 0.6109, Val Loss: 0.6588, Val Accuracy: 0.5758\n",
      "Epoch [98/500], Loss: 0.6092\n",
      "Epoch 98 Total Loss: 7.1994, Accuracy: 63.85%\n",
      "Epoch [98/500], Train Loss: 0.6092, Val Loss: 0.6560, Val Accuracy: 0.5758\n",
      "Epoch [99/500], Loss: 0.6075\n",
      "Epoch 99 Total Loss: 7.1790, Accuracy: 63.85%\n",
      "Epoch [99/500], Train Loss: 0.6075, Val Loss: 0.6528, Val Accuracy: 0.5758\n",
      "Epoch [100/500], Loss: 0.6057\n",
      "Epoch 100 Total Loss: 7.1586, Accuracy: 63.85%\n",
      "Epoch [100/500], Train Loss: 0.6057, Val Loss: 0.6501, Val Accuracy: 0.5758\n",
      "Epoch [101/500], Loss: 0.6043\n",
      "Epoch 101 Total Loss: 7.1417, Accuracy: 65.38%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 47\u001b[0m\n\u001b[1;32m     45\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m inputs, clinical, labels \u001b[38;5;129;01min\u001b[39;00m val_loader:\n\u001b[1;32m     48\u001b[0m         inputs, clinical, labels \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     49\u001b[0m             inputs\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[1;32m     50\u001b[0m             clinical\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[1;32m     51\u001b[0m             labels\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[1;32m     52\u001b[0m         )\n\u001b[1;32m     53\u001b[0m         image_output, mlp_output \u001b[38;5;241m=\u001b[39m model(inputs, clinical)\n",
      "File \u001b[0;32m~/anaconda3/envs/meeg-learning/lib/python3.9/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/meeg-learning/lib/python3.9/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/meeg-learning/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/meeg-learning/lib/python3.9/site-packages/torch/utils/data/dataset.py:399\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[0;32m~/anaconda3/envs/meeg-learning/lib/python3.9/site-packages/torch/utils/data/dataset.py:399\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "Cell \u001b[0;32mIn[3], line 77\u001b[0m, in \u001b[0;36mDLMICustomDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     75\u001b[0m clinical_data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack((gender, age, lymph_count))\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# (num_images, channels, height, width)\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m, clinical_data, label\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=hyperparameters[\"learning_rate\"])\n",
    "num_epochs = hyperparameters[\"num_epochs\"]\n",
    "model = model.to(device)\n",
    "best_loss = float(\"inf\")\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    for inputs, clinical, labels in train_loader:\n",
    "        inputs, clinical, labels = (\n",
    "            inputs.to(device),\n",
    "            clinical.to(device),\n",
    "            labels.to(device),\n",
    "        )\n",
    "        optimizer.zero_grad()\n",
    "        image_output, mlp_output = model(inputs, clinical)\n",
    "        labels = labels.view(image_output.shape).float()\n",
    "        loss = model.loss_function(image_output, mlp_output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        combined_output = (\n",
    "            torch.sigmoid(image_output) + torch.sigmoid(mlp_output)\n",
    "        ) / 2  # After the calculation of loss, predict the label using activation function\n",
    "        predicted_labels = torch.round(combined_output)\n",
    "        correct = (predicted_labels == labels).sum().item()\n",
    "        total_correct += correct\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n",
    "    accuracy = total_correct / total_samples\n",
    "    print(\n",
    "        \"Epoch {} Total Loss: {:.4f}, Accuracy: {:.2f}%\".format(\n",
    "            epoch + 1, running_loss / len(train_loader), accuracy * 100\n",
    "        )\n",
    "    )\n",
    "    writer.add_scalar(\"Loss/train\", epoch_loss, epoch)\n",
    "    writer.add_scalar(\"Accuracy/train\", accuracy, epoch)\n",
    "    # Validation\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, clinical, labels in val_loader:\n",
    "            inputs, clinical, labels = (\n",
    "                inputs.to(device),\n",
    "                clinical.to(device),\n",
    "                labels.to(device),\n",
    "            )\n",
    "            image_output, mlp_output = model(inputs, clinical)\n",
    "            labels = labels.view(image_output.shape).float()\n",
    "            loss = model.loss_function(image_output, mlp_output, labels)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            combined_output = (\n",
    "                torch.sigmoid(image_output) + torch.sigmoid(mlp_output)\n",
    "            ) / 2\n",
    "            predicted_labels = torch.round(combined_output)\n",
    "            correct += (predicted_labels == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    val_loss = val_loss / len(val_loader.dataset)\n",
    "    val_accuracy = correct / total\n",
    "    writer.add_scalar(\"Loss/validation\", val_loss, epoch)\n",
    "    writer.add_scalar(\"Accuracy/validation\", val_accuracy, epoch)\n",
    "    print(\n",
    "        f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {epoch_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\"\n",
    "    )\n",
    "\n",
    "    if epoch_loss < best_loss:\n",
    "        best_loss = epoch_loss\n",
    "        unchanged_count = 0\n",
    "    else:\n",
    "        unchanged_count += 1\n",
    "\n",
    "    if unchanged_count >= 5:\n",
    "        print(\"Loss has not changed for 5 consecutive epochs. Stopping training.\")\n",
    "        break\n",
    "\n",
    "    torch.save(\n",
    "        {\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            \"loss\": epoch_loss,\n",
    "            \"hyperparameters\": hyperparameters,\n",
    "        },\n",
    "        f\"{log_dir}/trained_model_epoch_{epoch+1}.pth\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(f\"logs/2024-03-27_23-20-25/trained_model_epoch_100.pth\")\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "# test\n",
    "model.eval()  # Set model to evaluation mode\n",
    "val_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    predicted_labels_list = []\n",
    "    for inputs, clinical, labels in train_loader:\n",
    "        inputs, clinical, labels = (\n",
    "            inputs.to(device),\n",
    "            clinical.to(device),\n",
    "            labels.to(device),\n",
    "        )\n",
    "        image_output, mlp_output = model(inputs, clinical)\n",
    "        labels = labels.view(image_output.shape).float()\n",
    "        loss = model.loss_function(image_output, mlp_output, labels)\n",
    "        val_loss += loss.item() * inputs.size(0)\n",
    "        combined_output = (torch.sigmoid(image_output) + torch.sigmoid(mlp_output)) / 2\n",
    "        predicted_labels = torch.round(combined_output)\n",
    "        predicted_labels_list.append(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy: 0.47916666666666663\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "# Concatenate predicted labels from all batches\n",
    "predicted_labels_tensor = torch.cat(predicted_labels_list)\n",
    "# Convert predicted labels tensor to numpy array\n",
    "predicted_labels_np = np.squeeze(predicted_labels_tensor.cpu().numpy())\n",
    "# Convert true labels tensor to numpy array\n",
    "true_labels_np = torch.cat([labels for _, _, labels in train_loader]).cpu().numpy()\n",
    "# Calculate balanced accuracy\n",
    "balanced_acc = balanced_accuracy_score(true_labels_np, predicted_labels_np)\n",
    "print(f\"Balanced Accuracy: {balanced_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_tensor = torch.cat(predicted_labels_list, dim=0)\n",
    "combined_tensor.shape\n",
    "combined_array = combined_tensor.cpu().numpy()\n",
    "ID = test_dataset.data.ID.to_numpy()\n",
    "ID = ID[:, np.newaxis]\n",
    "result_array = np.concatenate((ID, combined_array), axis=1)\n",
    "result_df = pd.DataFrame(result_array)\n",
    "result_df.columns = [\"ID\", \"Predicted\"]\n",
    "result_df[\"Predicted\"] = result_df[\"Predicted\"].astype(int)\n",
    "result_df.to_csv(\"output4.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meeg-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
