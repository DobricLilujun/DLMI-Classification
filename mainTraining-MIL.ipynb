{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIL - Multi instance Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233773/1677006143.py:28: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import copy\n",
    "import re\n",
    "import yaml\n",
    "import uuid\n",
    "import warnings\n",
    "import time\n",
    "import inspect\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import partial, reduce\n",
    "from random import shuffle\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, Resize\n",
    "from torchvision.models.resnet import ResNet, BasicBlock\n",
    "from torchvision.datasets import MNIST\n",
    "from tqdm.autonotebook import tqdm\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn import metrics as mtx\n",
    "from sklearn import model_selection as ms\n",
    "import os\n",
    "import shutil\n",
    "import warnings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import torch.nn.init as init\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "\n",
    "def calculate_age(dob_str):\n",
    "    formats = [\"%m/%d/%Y\", \"%d-%m-%Y\"]  # Two different format at the same time!\n",
    "    for format_string in formats:\n",
    "        try:\n",
    "            dob_date = datetime.strptime(dob_str, format_string)\n",
    "            current_date = datetime.now()\n",
    "            age = (\n",
    "                current_date.year\n",
    "                - dob_date.year\n",
    "                - (\n",
    "                    (current_date.month, current_date.day)\n",
    "                    < (dob_date.month, dob_date.day)\n",
    "                )\n",
    "            )\n",
    "            return age\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "\n",
    "def encode_gender(gender):\n",
    "    if gender == \"F\" or gender == \"f\":  # Two different gender value F and f ....\n",
    "        return 0\n",
    "    elif gender == \"M\" or gender == \"m\":\n",
    "        return 1\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Invalid gender value. Expected 'F' or 'M', but received: {}\".format(gender)\n",
    "        )\n",
    "\n",
    "\n",
    "class DLMICustomDataset(Dataset):\n",
    "    def __init__(self, data, transform=None, flag=\"trainset\", max_images=80):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "        self.flag = flag\n",
    "        self.max_images = max_images\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        patient_ID = self.data.iloc[idx, 1]\n",
    "        img_path_folder = \"data/raw/\" + self.flag + \"/\" + str(patient_ID) + \"/\"\n",
    "\n",
    "        images = []\n",
    "        images_loaded = 0\n",
    "        for filename in os.listdir(img_path_folder):\n",
    "            if filename.endswith(\".jpg\"):\n",
    "                img_path = os.path.join(img_path_folder, filename)\n",
    "                image = Image.open(img_path).convert(\"RGB\")\n",
    "                if self.transform:\n",
    "                    image = self.transform(image)\n",
    "                images.append(image)\n",
    "                images_loaded += 1\n",
    "                if (\n",
    "                    images_loaded >= self.max_images\n",
    "                ):  # Stop loading if max_images reached\n",
    "                    break\n",
    "        if len(images) == 0:\n",
    "            images.append(torch.zeros((3, 224, 224)))  # Placeholder image\n",
    "\n",
    "        while len(images) < self.max_images:\n",
    "            random_image = random.choice(images)\n",
    "            images.append(random_image)\n",
    "\n",
    "        label = torch.tensor(self.data.iloc[idx, 2])\n",
    "        gender = torch.tensor(encode_gender(self.data.iloc[idx, 3]), dtype=torch.long)\n",
    "        age = torch.tensor(calculate_age(self.data.iloc[idx, 4]), dtype=torch.float32)\n",
    "        lymph_count = torch.tensor(self.data.iloc[idx, 5], dtype=torch.float32)\n",
    "        clinical_data = torch.stack((gender, age, lymph_count))\n",
    "        # (num_images, channels, height, width)\n",
    "        return torch.stack(images), clinical_data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MILModel(nn.Module):\n",
    "    def __init__(self, mlp_input_dim, mlp_hidden_dim):\n",
    "        super(MILModel, self).__init__()\n",
    "        self.resnet50 = models.resnet50(pretrained=True)\n",
    "        for param in self.resnet50.parameters():\n",
    "            param.requires_grad = False\n",
    "        num_ftrs = self.resnet50.fc.in_features\n",
    "        self.resnet50.fc = nn.Linear(num_ftrs, num_ftrs)  # One trainable layers\n",
    "        self.linear_classifier = nn.Sequential(\n",
    "            nn.Linear(num_ftrs, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1),\n",
    "        )  # One classifier with bias\n",
    "        self.mlp = MLP(input_dim=mlp_input_dim, hidden_dim=mlp_hidden_dim, output_dim=1)\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "    # Batch imaging forwarding for bags batchsize*imagesnum*channel*width * height\n",
    "    def forward_images(self, image_data):\n",
    "        score_output = []\n",
    "        for batch in image_data:\n",
    "            batch_encoded_images = []\n",
    "            for image in batch:\n",
    "                image = image.unsqueeze(0)\n",
    "                with torch.no_grad():\n",
    "                    features = self.resnet50(image)\n",
    "                    # Mean pooling to do max pooling or LSE pooling\n",
    "                batch_encoded_images.append(features)\n",
    "            feature_extracted = torch.stack(batch_encoded_images)\n",
    "            features = torch.mean(feature_extracted, dim=0)\n",
    "            score_output.append(self.linear_classifier(features).view(-1))\n",
    "        return self.activation(torch.stack(score_output))\n",
    "\n",
    "    def forward(self, image_data, clinical_data):\n",
    "        batch_size, num_images, channels, height, width = image_data.size()\n",
    "        image_output = self.forward_images(image_data)\n",
    "        mlp_output = self.mlp(clinical_data)\n",
    "        return image_output, mlp_output\n",
    "\n",
    "    def loss_function(self, image_output, clinical_output, labels):\n",
    "        image_loss = F.binary_cross_entropy_with_logits(image_output, labels)\n",
    "        clinical_loss = F.binary_cross_entropy_with_logits(clinical_output, labels)\n",
    "        return (image_loss + clinical_loss) / 2\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.activate = nn.Sigmoid()\n",
    "\n",
    "        # Initialize the weights for the linear layers\n",
    "        init.xavier_uniform_(self.fc1.weight)\n",
    "        init.xavier_uniform_(self.fc2.weight)\n",
    "        init.xavier_uniform_(self.fc3.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return self.activate(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(outputs, labels):\n",
    "    predicted_classes = torch.argmax(outputs, dim=1)\n",
    "    true_classes = torch.argmax(labels, dim=1)\n",
    "    accuracy = (predicted_classes == true_classes).float().mean().item()\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trianing is on cuda\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import DatasetFolder\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import json\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Trianing is on \" + str(device))\n",
    "# Define hyperparameters\n",
    "hyperparameters = {\n",
    "    \"mlp_input_dim\": 3,\n",
    "    \"mlp_hidden_dim\": 300,\n",
    "    \"learning_rate\": 0.00001,\n",
    "    \"batch_size\": 10,\n",
    "    \"num_epochs\": 100,\n",
    "}\n",
    "\n",
    "model = MILModel(\n",
    "    mlp_input_dim=hyperparameters[\"mlp_input_dim\"],\n",
    "    mlp_hidden_dim=hyperparameters[\"mlp_hidden_dim\"],\n",
    ").to(device)\n",
    "\n",
    "with open(f\"hyperparameters.json\", \"w\") as json_file:\n",
    "    json.dump(hyperparameters, json_file)\n",
    "\n",
    "current_time = time.strftime(\"%Y-%m-%d_%H-%M-%S\", time.localtime())\n",
    "log_dir = os.path.join(\"logs\", current_time)\n",
    "writer = SummaryWriter(log_dir)\n",
    "\n",
    "data = pd.read_csv(\n",
    "    \"/home/lujun/local/DLMI-Classification/data/raw/clinical_annotation.csv\"\n",
    ")\n",
    "train_data = data[data[\"LABEL\"] != -1]\n",
    "test_data = data[data[\"LABEL\"] == -1]\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# training : validation : test = 130 : 33 : 42\n",
    "training_dataset = DLMICustomDataset(\n",
    "    data=train_data, transform=transform, flag=\"trainset\"\n",
    ")  # 130\n",
    "\n",
    "test_dataset = DLMICustomDataset(\n",
    "    data=test_data, transform=transform, flag=\"testset\"\n",
    ")  # 42\n",
    "\n",
    "train_size = int(0.8 * len(training_dataset))\n",
    "val_size = len(training_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(training_dataset, [train_size, val_size])\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=hyperparameters[\"batch_size\"], shuffle=True\n",
    ")  # 130\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=hyperparameters[\"batch_size\"], shuffle=False\n",
    ")  # 33\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n",
    "# Every item: max-images * channel number * width * height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.6254\n",
      "Epoch 1 Total Loss: 1.2508, Accuracy: 53.85%\n",
      "Epoch [1/100], Train Loss: 0.6254, Val Loss: 0.5854, Val Accuracy: 0.6061\n",
      "Epoch [2/100], Loss: 0.6264\n",
      "Epoch 2 Total Loss: 1.2528, Accuracy: 66.92%\n",
      "Epoch [2/100], Train Loss: 0.6264, Val Loss: 0.5809, Val Accuracy: 0.7273\n",
      "Epoch [3/100], Loss: 0.6093\n",
      "Epoch 3 Total Loss: 1.2186, Accuracy: 62.31%\n",
      "Epoch [3/100], Train Loss: 0.6093, Val Loss: 0.5677, Val Accuracy: 0.7273\n",
      "Epoch [4/100], Loss: 0.6085\n",
      "Epoch 4 Total Loss: 1.2171, Accuracy: 60.00%\n",
      "Epoch [4/100], Train Loss: 0.6085, Val Loss: 0.5713, Val Accuracy: 0.7273\n",
      "Epoch [5/100], Loss: 0.5976\n",
      "Epoch 5 Total Loss: 1.1952, Accuracy: 71.54%\n",
      "Epoch [5/100], Train Loss: 0.5976, Val Loss: 0.6019, Val Accuracy: 0.5152\n",
      "Epoch [6/100], Loss: 0.6204\n",
      "Epoch 6 Total Loss: 1.2407, Accuracy: 53.08%\n",
      "Epoch [6/100], Train Loss: 0.6204, Val Loss: 0.5857, Val Accuracy: 0.5758\n",
      "Epoch [7/100], Loss: 0.6013\n",
      "Epoch 7 Total Loss: 1.2027, Accuracy: 63.08%\n",
      "Epoch [7/100], Train Loss: 0.6013, Val Loss: 0.5644, Val Accuracy: 0.7273\n",
      "Epoch [8/100], Loss: 0.6015\n",
      "Epoch 8 Total Loss: 1.2031, Accuracy: 63.85%\n",
      "Epoch [8/100], Train Loss: 0.6015, Val Loss: 0.5863, Val Accuracy: 0.5758\n",
      "Epoch [9/100], Loss: 0.6001\n",
      "Epoch 9 Total Loss: 1.2001, Accuracy: 62.31%\n",
      "Epoch [9/100], Train Loss: 0.6001, Val Loss: 0.5530, Val Accuracy: 0.7879\n",
      "Epoch [10/100], Loss: 0.6066\n",
      "Epoch 10 Total Loss: 1.2133, Accuracy: 61.54%\n",
      "Epoch [10/100], Train Loss: 0.6066, Val Loss: 0.5581, Val Accuracy: 0.7879\n",
      "Loss has not changed for 5 consecutive epochs. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=hyperparameters[\"learning_rate\"])\n",
    "num_epochs = hyperparameters[\"num_epochs\"]\n",
    "\n",
    "best_loss = float(\"inf\")\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    for inputs, clinical, labels in train_loader:\n",
    "        inputs, clinical, labels = (\n",
    "            inputs.to(device),\n",
    "            clinical.to(device),\n",
    "            labels.to(device),\n",
    "        )\n",
    "        optimizer.zero_grad()\n",
    "        image_output, mlp_output = model(inputs, clinical)\n",
    "        # labels.requires_grad = True\n",
    "        labels = labels.view(image_output.shape).float()\n",
    "        loss = model.loss_function(image_output, mlp_output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        combined_output = (image_output + mlp_output) / 2\n",
    "        predicted_labels = torch.round(combined_output)\n",
    "        correct = (predicted_labels == labels).sum().item()\n",
    "        total_correct += correct\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n",
    "    accuracy = total_correct / total_samples\n",
    "    print(\n",
    "        \"Epoch {} Total Loss: {:.4f}, Accuracy: {:.2f}%\".format(\n",
    "            epoch + 1, running_loss / len(train_loader), accuracy * 100\n",
    "        )\n",
    "    )\n",
    "    writer.add_scalar(\"Loss/train\", epoch_loss, epoch)\n",
    "    writer.add_scalar(\"Accuracy/train\", accuracy, epoch)\n",
    "    # Validation\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, clinical, labels in val_loader:\n",
    "            inputs, clinical, labels = (\n",
    "                inputs.to(device),\n",
    "                clinical.to(device),\n",
    "                labels.to(device),\n",
    "            )\n",
    "            image_output, mlp_output = model(inputs, clinical)\n",
    "            labels = labels.view(image_output.shape).float()\n",
    "            loss = model.loss_function(image_output, mlp_output, labels)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            combined_output = (image_output + mlp_output) / 2\n",
    "            predicted_labels = torch.round(combined_output)\n",
    "            correct += (predicted_labels == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    val_loss = val_loss / len(val_loader.dataset)\n",
    "    val_accuracy = correct / total\n",
    "    writer.add_scalar(\"Loss/validation\", val_loss, epoch)\n",
    "    writer.add_scalar(\"Accuracy/validation\", val_accuracy, epoch)\n",
    "    print(\n",
    "        f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {epoch_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\"\n",
    "    )\n",
    "\n",
    "    if epoch_loss < best_loss:\n",
    "        best_loss = epoch_loss\n",
    "        unchanged_count = 0\n",
    "    else:\n",
    "        unchanged_count += 1\n",
    "\n",
    "    if unchanged_count >= 5:\n",
    "        print(\"Loss has not changed for 5 consecutive epochs. Stopping training.\")\n",
    "        break\n",
    "\n",
    "    torch.save(\n",
    "        {\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            \"loss\": epoch_loss,\n",
    "            \"hyperparameters\": hyperparameters,\n",
    "        },\n",
    "        f\"trained_model_epoch_{epoch+1}.pth\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "model.eval()  # Set model to evaluation mode\n",
    "val_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    predicted_labels_list = []\n",
    "    for inputs, clinical, labels in test_loader:\n",
    "        inputs, clinical, labels = (\n",
    "            inputs.to(device),\n",
    "            clinical.to(device),\n",
    "            labels.to(device),\n",
    "        )\n",
    "        image_output, mlp_output = model(inputs, clinical)\n",
    "        labels = labels.view(image_output.shape).float()\n",
    "        loss = model.loss_function(image_output, mlp_output, labels)\n",
    "        val_loss += loss.item() * inputs.size(0)\n",
    "        combined_output = (image_output + mlp_output) / 2\n",
    "        predicted_labels = torch.round(combined_output)\n",
    "        predicted_labels_list.append(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [4, 1] at entry 0 and [2, 1] at entry 10",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredicted_labels_list\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [4, 1] at entry 0 and [2, 1] at entry 10"
     ]
    }
   ],
   "source": [
    "torch.stack(predicted_labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels_list[9].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_tensor = torch.cat(predicted_labels_list, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([42, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_array = combined_tensor.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = test_dataset.data.ID.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = ID[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_array = np.concatenate((ID, combined_array), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(result_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.columns = [\"ID\", \"Predicted\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df[\"Predicted\"] = result_df[\"Predicted\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(\"output2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meeg-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
